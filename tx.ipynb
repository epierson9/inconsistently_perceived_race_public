{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG (leave only one uncommented)\n",
    "# dr_race_col = 'driver_race' # don't use - this is not the officer's perception\n",
    "dr_race_col = 'driver_race' # standardize_cols replaces driver_race with capitalized driver_race_raw, so it is ok to use this\n",
    "\n",
    "capitalize_dr_race_col = False # Texas driver_race cols aren't capitalized, so capitalize them\n",
    "\n",
    "# Don't use tx_processed: tx_processed is after processing the raw data, which doesn't have the driver_race or driver_race_raw columns yet\n",
    "# Use tx_processed_driver_race_cols or the TX-clean.csv from the raw_openpolicing_data folder\n",
    "config = { # 2016-2017 data only\n",
    "    \"grouping_keys\": ['HA_N_FIRST_DRVR', 'HA_N_LAST_DRVR', 'HA_A_ADDRESS_DRVR', 'HA_A_CITY_DRVR', 'HA_A_STATE_DRVR', 'HA_A_ZIP_DRVR'],\n",
    "    \"descript\": dr_race_col,\n",
    "    \"base_path\": 'replace-with-path-to-this-directory',\n",
    "    \"starting_file_name\": 'path-to-TX-data.csv',\n",
    "    \"grouped_csv_name\": 'tx_processed_grouped_driver_race_raw.csv',\n",
    "    \"hispanic_white_drivers_only_csv_name\": f\"tx_processed_hispanic_white_drivers_{dr_race_col}.csv\",\n",
    "    \"only_after_2016\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base path directory\n",
    "base_path = config['base_path']\n",
    "\n",
    "%cd $base_path\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "from policing_data_expl import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Raw Data and Clean Data Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = config['starting_file_name']\n",
    "dtypes_dict = {k:str for k in config['grouping_keys']}\n",
    "tx_data = standardize_cols('TX', pd.read_csv(filepath, dtype=dtypes_dict))\n",
    "\n",
    "if config['only_after_2016']:\n",
    "    # only take rows that happened in the year 2016 and 2017\n",
    "    before2016_mask = tx_data['date'].apply(lambda x: str(x)[:4] != '2016' and str(x)[:4] != '2017')\n",
    "    only_2016_2017 = tx_data['date'].apply(lambda x: str(x)[:4] == '2016' or str(x)[:4] == '2017')\n",
    "    b2016 = tx_data[before2016_mask]\n",
    "    a2016 = tx_data[only_2016_2017]\n",
    "    tx_data = a2016\n",
    "\n",
    "print(f'Rows: {len(tx_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking race discordance between what's written and the corrected versions\n",
    "# tx_data_copy = tx_data.copy()\n",
    "# tx_data_copy['year_month'] = tx_data_copy['date'].apply(lambda x: str(x)[:7])\n",
    "# for group, item in tx_data_copy.groupby('year_month'):\n",
    "#     print(group, (item['driver_race'] != item['driver_race_raw']).sum() / len(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'completeness' (how many non-nan values there are) per column\n",
    "for column in tx_data.columns:\n",
    "    print(column)\n",
    "    print('  ', get_percent_complete_column(tx_data, column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_complete_cols(tx_data, config['grouping_keys'], driver_race_col=dr_race_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Filtered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tx = group_df_by(tx_data, config['grouping_keys'], driver_race_col=dr_race_col, csv_filename='tx_raw_with_driver_id_' + config['descript'] + '.csv')\n",
    "\n",
    "def tx_cond(name, entries):\n",
    "    \"\"\"\n",
    "    Only keep drivers \n",
    "    - with at least 2 entries (=at least 2 stops) and no more than 10 stops\n",
    "    - assume non-null HA_N_FIRST_DRVR, HA_N_LAST_DRVR, HA_A_ADDRESS_DRVR, HA_A_CITY_DRVR, HA_A_STATE_DRVR, HA_A_ZIP_DRVR (=valid unique identifying features)\n",
    "    \"\"\"\n",
    "    f, l, a, c, s, z = name\n",
    "    return len(entries) >= 2 and len(entries) <= 10\n",
    "        \n",
    "csv_name = config['grouped_csv_name']\n",
    "check_cond(grouped_tx, tx_cond, csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = config['grouped_csv_name']\n",
    "txgrouped_csv = pd.read_csv(csv_name)\n",
    "\n",
    "if capitalize_dr_race_col:\n",
    "    # with the processed csv, the driver_race_raw are lowercased, so capitalize them\n",
    "    txgrouped_csv['driver_race_raw'] = txgrouped_csv['driver_race_raw'].apply(lambda x: str(x).capitalize())\n",
    "\n",
    "tx_grouped = txgrouped_csv.groupby(config['grouping_keys'])\n",
    "\n",
    "print(\"#rows of individuals stopped more than once:\", len(txgrouped_csv))\n",
    "print(\"#individuals stopped more than once:\", len(tx_grouped))\n",
    "\n",
    "calc_mean_med_max_stops(tx_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because Texas is only looking at 2016 and 2017 data, confirm that here\n",
    "txgrouped_csv['date'].apply(lambda x: str(x)[:4]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_racial_ambig(tx_grouped, driver_race_col=dr_race_col)\n",
    "\n",
    "enumerate_racial_ambig(tx_grouped, driver_race_col=dr_race_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txgrouped_csv.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Stats for Racially Ambiguous Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_race_dict = generate_person_race_dict(tx_grouped, driver_race_col=dr_race_col)\n",
    "# make the grouping_keys into a tuple so it can be used as a key per person in person_race_dict\n",
    "tuple_lst = [tuple(keys) for keys in txgrouped_csv[config['grouping_keys']].values.tolist()]\n",
    "race_str_col = [person_race_dict[(keys)] for keys in tuple_lst]\n",
    "\n",
    "# call this new column race_str\n",
    "txgrouped_with_race_str = txgrouped_csv.copy()\n",
    "txgrouped_with_race_str.insert(2, \"race_str\", race_str_col, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict_lst = get_state_stats(txgrouped_csv, race_str_col, config['grouping_keys'], driver_race_col=dr_race_col)\n",
    "\n",
    "plot_state_stats(stats_dict_lst, 'TX - ' + config['descript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove drivers with more than 10 stops\n",
    "tx_with_drivers_less_than_10_stops = txgrouped_csv.groupby(config['grouping_keys']).filter(lambda x: len(x) <= 10).reset_index()\n",
    "\n",
    "# make the grouping_keys into a tuple so it can be used as a key per person in person_race_dict\n",
    "tuple_lst = [tuple(keys) for keys in tx_with_drivers_less_than_10_stops[config['grouping_keys']].values.tolist()]\n",
    "race_str_col = [person_race_dict[(keys)] for keys in tuple_lst]\n",
    "\n",
    "# call this new column race_str\n",
    "# azgrouped_with_race_str = azgrouped_csv.copy()\n",
    "# azgrouped_with_race_str.insert(2, \"race_str\", race_str_col, False)\n",
    "\n",
    "stats_dict_lst = get_state_stats(tx_with_drivers_less_than_10_stops, race_str_col, config['grouping_keys'], dr_race_col)\n",
    "\n",
    "plot_state_stats(stats_dict_lst, 'TX - ' + config['descript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_unpaired(txgrouped_with_race_str, driver_race_col=dr_race_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_paired(tx_grouped, driver_race_col=dr_race_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# white-Hispanic Drivers and Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_str_cond = txgrouped_with_race_str['race_str'].map(lambda x:x in {\"Hispanic_White\"})\n",
    "hispanic_white_drivers = txgrouped_with_race_str.loc[txgrouped_with_race_str['search_conducted'].notnull() & race_str_cond]\n",
    "\n",
    "print(len(hispanic_white_drivers))\n",
    "print(config['hispanic_white_drivers_only_csv_name'])\n",
    "write_to_csv(hispanic_white_drivers, config['hispanic_white_drivers_only_csv_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txgrouped_with_race_str = pd.read_csv(config['hispanic_white_drivers_only_csv_name'])\n",
    "txgrouped_with_race_str['officer_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_hispanic_white_grouped = txgrouped_with_race_str.groupby(config['grouping_keys'])\n",
    "print(f'entries: {len(txgrouped_with_race_str)}')\n",
    "print(f'individuals: {len(tx_hispanic_white_grouped)}')\n",
    "calc_mean_med_max_stops(tx_hispanic_white_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: TX only has search data from 2016 and no arrest data\n",
    "txgrouped_with_race_str['date'].apply(lambda x: str(x)[:4]).value_counts()\n",
    "\n",
    "txgrouped_with_race_str.loc[txgrouped_with_race_str['search_conducted'].notnull()]['date'].apply(lambda x: str(x)[:4]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = regress(txgrouped_with_race_str, dep_var='search_conducted', cols=[], controls=[], model_name='No controls', useFixedEffects=True, stop_date_col='date', driver_race_col=dr_race_col, stop_time_col='time')\n",
    "res2 = regress(txgrouped_with_race_str, dep_var='search_conducted', cols=['hour_of_day'], controls=['hour_of_day'], model_name='Control for hour of day (linear)', useFixedEffects=True, stop_date_col='date', driver_race_col=dr_race_col, stop_time_col='time')\n",
    "res3 = regress(txgrouped_with_race_str, dep_var='search_conducted', cols=['hour_of_day'], controls=['hour_of_day', 'I(hour_of_day**2)', 'I(hour_of_day**3)', 'I(hour_of_day**4)'], model_name='Control for hour of day (quartic)', useFixedEffects=True, stop_date_col='date', driver_race_col=dr_race_col, stop_time_col='time')\n",
    "res4 = regress(txgrouped_with_race_str, dep_var='search_conducted', cols=['county_fips'], controls=['C(county_fips)'], model_name='Control for county - drop absorbed', useFixedEffects=True, stop_date_col='date', driver_race_col=dr_race_col, stop_time_col='time', drop_absorbed=True)\n",
    "res5 = regress(txgrouped_with_race_str, dep_var='search_conducted', cols=['officer_id'], controls=['C(officer_id)'], model_name='Control for officer id - drop absorbed', useFixedEffects=True, stop_date_col='date', driver_race_col=dr_race_col, stop_time_col='time', drop_absorbed=True)\n",
    "\n",
    "make_sensitivity_dot_plot([res1, res2, res3, res4, res5], coef_to_plot = 'Hispanic', title='Sensitivity to controls in Texas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressions that don't yield much\n",
    "# res1 = regress(txgrouped_with_race_str, dep_var='contraband_found', cols=[], controls=[], model_name='No controls (contraband found rate)', useFixedEffects=True, stop_date_col='date', driver_race_col='driver_race_raw')\n",
    "# res2 = regress(non_null_outcome, cols=[], controls=[], dep_var='citation_given', model_name='no controls (citation rate)', useFixedEffects=True, stop_date_col='date', driver_race_col='driver_race_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Years of Data in the Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_complete = pd.read_csv(config['grouped_csv_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_complete['date'].apply(lambda x: str(x)[:4]).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_hispanic_white = pd.read_csv(config['hispanic_white_drivers_only_csv_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_hispanic_white['date'].apply(lambda x: str(x)[:4]).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing a Couple Subsets of the Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_search_rates_comparison('TX', 'search_conducted', tx_data, txgrouped_csv, txgrouped_with_race_str, driver_race_col=dr_race_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Drivers, white or Hispanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_5_col_values(tx_data, 'violation', driver_race_col=dr_race_col)\n",
    "plot_top_5_col_values(tx_data, 'county_name', driver_race_col=dr_race_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiply Stopped Drivers, white or Hispanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_5_col_values(txgrouped_csv, 'violation', driver_race_col=dr_race_col)\n",
    "plot_top_5_col_values(txgrouped_csv, 'county_name', driver_race_col=dr_race_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiply Stopped Drivers with white/Hispanic Racial Ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_5_col_values(txgrouped_with_race_str, 'violation', driver_race_col=dr_race_col)\n",
    "plot_top_5_col_values(txgrouped_with_race_str, 'county_name', driver_race_col=dr_race_col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv2] *",
   "language": "python",
   "name": "conda-env-.conda-myenv2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
